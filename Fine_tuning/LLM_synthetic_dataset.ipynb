{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "da72fe855c6a43209b54e641a415ca64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22d0e3f178bc4ce7a7197fa4841e29ce",
              "IPY_MODEL_67170c8edf6f40d4a0bb33b85c0e61af",
              "IPY_MODEL_390d7e8216274761aba0a1fa8e0c11b7"
            ],
            "layout": "IPY_MODEL_7ed43c4fd189478b9a8b5ba3a11b3899"
          }
        },
        "22d0e3f178bc4ce7a7197fa4841e29ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81a3113086854accbc8138a47d7cfcba",
            "placeholder": "​",
            "style": "IPY_MODEL_8fdd41233a2b4482a436aae7cc6ed246",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "67170c8edf6f40d4a0bb33b85c0e61af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd2b274d64754acbb38cca84d6218a2f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cfa62da674534409bfa6a17d978bd1a1",
            "value": 2
          }
        },
        "390d7e8216274761aba0a1fa8e0c11b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e066452acde04c3ea4173d47ce8250c8",
            "placeholder": "​",
            "style": "IPY_MODEL_ebd241a51e524fe1af07f784f1a334ca",
            "value": " 2/2 [01:08&lt;00:00, 31.24s/it]"
          }
        },
        "7ed43c4fd189478b9a8b5ba3a11b3899": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81a3113086854accbc8138a47d7cfcba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fdd41233a2b4482a436aae7cc6ed246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd2b274d64754acbb38cca84d6218a2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfa62da674534409bfa6a17d978bd1a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e066452acde04c3ea4173d47ce8250c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebd241a51e524fe1af07f784f1a334ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "801d21c7454246c09e846e264699293d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e872b7ff07dd484ca97328d0c9955184",
              "IPY_MODEL_b5e62c48ae6442528124af5a245df508",
              "IPY_MODEL_f917ab90728f4822be54446a6c7135f7"
            ],
            "layout": "IPY_MODEL_8a996455481642c4999ea995e8329be2"
          }
        },
        "e872b7ff07dd484ca97328d0c9955184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22fdf4933a8b40c1829d2e53ae1e11b8",
            "placeholder": "​",
            "style": "IPY_MODEL_3941f692eb684d08ae71ddf7252f75e5",
            "value": "Loading checkpoint shards:   0%"
          }
        },
        "b5e62c48ae6442528124af5a245df508": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfa4ea7264924765965583c93f470259",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1bd478563ef4333a9cd9b63ae0505aa",
            "value": 0
          }
        },
        "f917ab90728f4822be54446a6c7135f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_697c40dfdbe647fba93ffe676d760c3f",
            "placeholder": "​",
            "style": "IPY_MODEL_6849abaf9fac4b27be2147e89383f00e",
            "value": " 0/2 [00:00&lt;?, ?it/s]"
          }
        },
        "8a996455481642c4999ea995e8329be2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22fdf4933a8b40c1829d2e53ae1e11b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3941f692eb684d08ae71ddf7252f75e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfa4ea7264924765965583c93f470259": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1bd478563ef4333a9cd9b63ae0505aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "697c40dfdbe647fba93ffe676d760c3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6849abaf9fac4b27be2147e89383f00e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2dfb76546744b809d781d4f31dee7c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_932f399705a3472a9c7721f3fc88dfb9",
              "IPY_MODEL_b408a1baf6424c669ca099fb3ae0b94b",
              "IPY_MODEL_9821a6c57bed4182924891b6949debe8"
            ],
            "layout": "IPY_MODEL_b3f4f561c2544e59843747bccc973668"
          }
        },
        "932f399705a3472a9c7721f3fc88dfb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d97fcf6368b47fc900d62397a179dff",
            "placeholder": "​",
            "style": "IPY_MODEL_70bb3c7580684990adf0295c188da7a4",
            "value": "Downloading data files: 100%"
          }
        },
        "b408a1baf6424c669ca099fb3ae0b94b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f44ac9c12c2e487d8296797bd5ea6871",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c18249877dd4a5eb9f979915bb2189a",
            "value": 1
          }
        },
        "9821a6c57bed4182924891b6949debe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69c2b44e98a64b0baf07414ba74aeb80",
            "placeholder": "​",
            "style": "IPY_MODEL_89b220b66ebf40629e4b3bd7a29341c3",
            "value": " 1/1 [00:00&lt;00:00, 31.29it/s]"
          }
        },
        "b3f4f561c2544e59843747bccc973668": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d97fcf6368b47fc900d62397a179dff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70bb3c7580684990adf0295c188da7a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f44ac9c12c2e487d8296797bd5ea6871": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c18249877dd4a5eb9f979915bb2189a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69c2b44e98a64b0baf07414ba74aeb80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89b220b66ebf40629e4b3bd7a29341c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "769107a5a6b741918915bab7e1a96ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e3032a49bbe42b0b6439686582e6adf",
              "IPY_MODEL_167122d29fbb411093844cd41531db71",
              "IPY_MODEL_99df95928b6847ef89b2737c8c83282d"
            ],
            "layout": "IPY_MODEL_a2b46ea30f6c4e21b4edb5db2bc72d25"
          }
        },
        "8e3032a49bbe42b0b6439686582e6adf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e66ad210de14c518638e83f7bdc8bf3",
            "placeholder": "​",
            "style": "IPY_MODEL_9d90bba482644783a07d6271a7012f03",
            "value": "Extracting data files: 100%"
          }
        },
        "167122d29fbb411093844cd41531db71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c063ef7920564637855fe800af2efd44",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed8b8e688f1644bba906e68270ceb16a",
            "value": 1
          }
        },
        "99df95928b6847ef89b2737c8c83282d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54ffc0a131da4cefaaca9e44a00c3da0",
            "placeholder": "​",
            "style": "IPY_MODEL_dc12266d7f544a0ca2fbde49e689838c",
            "value": " 1/1 [00:00&lt;00:00, 40.89it/s]"
          }
        },
        "a2b46ea30f6c4e21b4edb5db2bc72d25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e66ad210de14c518638e83f7bdc8bf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d90bba482644783a07d6271a7012f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c063ef7920564637855fe800af2efd44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed8b8e688f1644bba906e68270ceb16a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54ffc0a131da4cefaaca9e44a00c3da0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc12266d7f544a0ca2fbde49e689838c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a698f236f5e444db312a34f7cfde112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c1b1eaac80d47a8bbdc0a26960662e6",
              "IPY_MODEL_db77b0d5e039440a8a16856a8eba85a9",
              "IPY_MODEL_69df5c341fd64a36a64fb03450902308"
            ],
            "layout": "IPY_MODEL_71f426aef3a7488787b64056cb12c091"
          }
        },
        "4c1b1eaac80d47a8bbdc0a26960662e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50bde8b4303d4756908316e5876b600f",
            "placeholder": "​",
            "style": "IPY_MODEL_c20dda6ef1de477b9e7646ce98fab41f",
            "value": "Generating train split: "
          }
        },
        "db77b0d5e039440a8a16856a8eba85a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b43dd01294274cdbba1a4faa519ee6f9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_449cfcf1a35443d5b39103962913a371",
            "value": 1
          }
        },
        "69df5c341fd64a36a64fb03450902308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67184b881bbe47e4aed2a465a4633fda",
            "placeholder": "​",
            "style": "IPY_MODEL_e9a66ca4510f48ad9146874a0d7145da",
            "value": " 1000/0 [00:00&lt;00:00, 17800.23 examples/s]"
          }
        },
        "71f426aef3a7488787b64056cb12c091": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50bde8b4303d4756908316e5876b600f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c20dda6ef1de477b9e7646ce98fab41f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b43dd01294274cdbba1a4faa519ee6f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "449cfcf1a35443d5b39103962913a371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67184b881bbe47e4aed2a465a4633fda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9a66ca4510f48ad9146874a0d7145da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "271e05ea",
        "outputId": "2a2d903b-be09-414d-fe1d-2008402be441"
      },
      "source": [
        "%pip install -U bitsandbytes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl (67.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bitsandbytes-0.46.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvidia"
                ]
              },
              "id": "7a81fee02cf54a21bfa3cb4e7f8a3089"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from typing import Tuple, Dict, List\n",
        "\n",
        "\n",
        "class FatigueDatasetGenerator:\n",
        "    def __init__(self, samples_per_case: int = 300):\n",
        "        self.samples_per_case = samples_per_case\n",
        "        self.feature_ranges = self.define_feature_ranges()\n",
        "        self.intervention_lookup = self.define_intervention_lookup()\n",
        "\n",
        "    def define_feature_ranges(self) -> Dict[str, Dict[str, Tuple[float, float]]]:\n",
        "        \"\"\"Define realistic value ranges for each feature by fatigue class (Low/Moderate/High)\"\"\"\n",
        "        return {\n",
        "            \"Blink Rate\": {\"Low\": (10, 15), \"Moderate\": (15, 18), \"High\": (18, 30)},\n",
        "            \"Yawning Rate\": {\"Low\": (0, 0), \"Moderate\": (1, 1), \"High\": (2, 5)},\n",
        "            \"PERCLOS\": {\"Low\": (0, 15), \"Moderate\": (15, 30), \"High\": (30, 60)},\n",
        "            \"SDLP\": {\"Low\": (0, 20), \"Moderate\": (20, 35), \"High\": (35, 50)},  # cm\n",
        "            \"Steering Entropy\": {\"Low\": (0, 1), \"Moderate\": (1, 3), \"High\": (3, 5)},\n",
        "            \"Lane Keeping Ratio\": {\"Low\": (0, 0.7), \"Moderate\": (0.7, 0.85), \"High\": (0.85, 1)},\n",
        "            \"Lane Departure Frequency\": {\"Low\": (0, 2.5), \"Moderate\": (2.5, 3.5), \"High\": (3.5, 6)},\n",
        "            \"SRR\": {\"Low\": (0, 15), \"Moderate\": (15, 25), \"High\": (25, 35)},\n",
        "            \"SAV\": {\"Low\": (1, 4), \"Moderate\": (5, 9), \"High\": (10, 15)}\n",
        "        }\n",
        "\n",
        "    def define_intervention_lookup(self) -> Dict[Tuple[str, str, str], Dict[str, str]]:\n",
        "        \"\"\"Define intervention rules based on CF, SF, LF fatigue levels\"\"\"\n",
        "        return {\n",
        "            (\"Low\", \"Low\", \"Low\"): {\n",
        "                \"fan\": \"off\", \"music\": \"off\", \"vibration\": \"off\",\n",
        "                \"reason\": \"No signs of fatigue detected. No intervention required.\"\n",
        "            },\n",
        "            (\"Moderate\", \"Low\", \"Low\"): {\n",
        "                \"fan\": \"level 2\", \"music\": \"off\", \"vibration\": \"off\",\n",
        "                \"reason\": \"Moderate visual fatigue may impair focus. Increased airflow helps maintain alertness without overstimulation.\"\n",
        "            },\n",
        "            (\"High\", \"Low\", \"Low\"): {\n",
        "                \"fan\": \"level 3\", \"music\": \"beep\", \"vibration\": \"Vibrate\",\n",
        "                \"reason\": \"Severe visual fatigue threatens awareness. Multi-modal alerts counter visual disengagement effectively.\"\n",
        "            },\n",
        "            (\"Low\", \"Moderate\", \"Moderate\"): {\n",
        "                \"fan\": \"level 2\", \"music\": \"off\", \"vibration\": \"off\",\n",
        "                \"reason\": \"Motor and lane variations suggest early fatigue. Moderate airflow stabilizes driver alertness.\"\n",
        "            },\n",
        "            (\"Moderate\", \"Moderate\", \"Moderate\"): {\n",
        "                \"fan\": \"level 2\", \"music\": \"beep\", \"vibration\": \"off\",\n",
        "                \"reason\": \"Combined visual and control fatigue detected. Fan and beep boost sensory engagement without physical feedback.\"\n",
        "            },\n",
        "            (\"High\", \"Moderate\", \"Moderate\"): {\n",
        "                \"fan\": \"level 3\", \"music\": \"beep\", \"vibration\": \"Vibrate\",\n",
        "                \"reason\": \"High fatigue across systems impairs control. Full intervention improves driver responsiveness and safety.\"\n",
        "            },\n",
        "            (\"Low\", \"High\", \"High\"): {\n",
        "                \"fan\": \"level 3\", \"music\": \"beep\", \"vibration\": \"Vibrate\",\n",
        "                \"reason\": \"Physical and lane instability despite visual alertness. Tactile and auditory cues reinforce driver control.\"\n",
        "            },\n",
        "            (\"Moderate\", \"High\", \"High\"): {\n",
        "                \"fan\": \"level 3\", \"music\": \"beep\", \"vibration\": \"Vibrate\",\n",
        "                \"reason\": \"Motor and lane fatigue with visual strain detected. Strong multi-sensory cues are required immediately.\"\n",
        "            },\n",
        "            (\"High\", \"High\", \"High\"): {\n",
        "                \"fan\": \"level 3\", \"music\": \"beep\", \"vibration\": \"Vibrate\",\n",
        "                \"reason\": \"Critical fatigue in all systems detected. Immediate and full intervention needed to ensure driver safety.\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def sample_feature(self, level: str, feature: str) -> float:\n",
        "        \"\"\"Sample a value for a feature based on its fatigue class\"\"\"\n",
        "        low, high = self.feature_ranges[feature][level]\n",
        "        return round(random.uniform(low, high), 2)\n",
        "\n",
        "    def generate_sample(self, cf: str, sf: str, lf: str, sample_id: int) -> Dict:\n",
        "        \"\"\"Generate one full synthetic sample\"\"\"\n",
        "        timestamp = datetime.utcnow().isoformat()\n",
        "        features = {\n",
        "            \"Blink Rate\": self.sample_feature(cf, \"Blink Rate\"),\n",
        "            \"Yawning Rate\": self.sample_feature(cf, \"Yawning Rate\"),\n",
        "            \"PERCLOS\": self.sample_feature(cf, \"PERCLOS\"),\n",
        "            \"SDLP\": self.sample_feature(lf, \"SDLP\"),\n",
        "            \"Steering Entropy\": self.sample_feature(sf, \"Steering Entropy\"),\n",
        "            \"Lane Keeping Ratio\": self.sample_feature(lf, \"Lane Keeping Ratio\"),\n",
        "            \"Lane Departure Frequency\": self.sample_feature(lf, \"Lane Departure Frequency\"),\n",
        "            \"SRR\": self.sample_feature(sf, \"SRR\"),\n",
        "            \"SAV\": self.sample_feature(sf, \"SAV\")\n",
        "        }\n",
        "\n",
        "        intervention = self.intervention_lookup.get((cf, sf, lf))\n",
        "        if not intervention:\n",
        "            return None\n",
        "\n",
        "        return {\n",
        "            \"ID\": sample_id,\n",
        "            \"timestamp\": timestamp,\n",
        "            \"features\": features,\n",
        "            \"CF\": cf,\n",
        "            \"SF\": sf,\n",
        "            \"LF\": lf,\n",
        "            \"intervention\": intervention\n",
        "        }\n",
        "\n",
        "    def generate_dataset(self) -> Tuple[List[Dict], pd.DataFrame]:\n",
        "        \"\"\"Generate full dataset as JSON list and DataFrame\"\"\"\n",
        "        dataset = []\n",
        "        records = []\n",
        "        sample_id = 1\n",
        "        fatigue_levels = [\"Low\", \"Moderate\", \"High\"]\n",
        "\n",
        "        for cf in fatigue_levels:\n",
        "            for sf in fatigue_levels:\n",
        "                for lf in fatigue_levels:\n",
        "                    combo = (cf, sf, lf)\n",
        "                    if combo not in self.intervention_lookup:\n",
        "                        continue\n",
        "                    for _ in range(self.samples_per_case):\n",
        "                        entry = self.generate_sample(cf, sf, lf, sample_id)\n",
        "                        if entry is None:\n",
        "                            continue\n",
        "                        dataset.append(entry)\n",
        "\n",
        "                        # Flatten for CSV\n",
        "                        flat = {\n",
        "                            \"ID\": entry[\"ID\"],\n",
        "                            \"timestamp\": entry[\"timestamp\"],\n",
        "                            **entry[\"features\"],\n",
        "                            \"CF\": cf,\n",
        "                            \"SF\": sf,\n",
        "                            \"LF\": lf,\n",
        "                            \"fan\": entry[\"intervention\"][\"fan\"],\n",
        "                            \"music\": entry[\"intervention\"][\"music\"],\n",
        "                            \"vibration\": entry[\"intervention\"][\"vibration\"],\n",
        "                            \"reason\": entry[\"intervention\"][\"reason\"]\n",
        "                        }\n",
        "                        records.append(flat)\n",
        "                        sample_id += 1\n",
        "\n",
        "        return dataset, pd.DataFrame(records)\n",
        "\n",
        "    def save(self, dataset: List[Dict], df: pd.DataFrame, json_path: str, csv_path: str):\n",
        "        \"\"\"Save dataset to JSON and CSV files\"\"\"\n",
        "        with open(json_path, \"w\") as f_json:\n",
        "            json.dump(dataset, f_json, indent=2)\n",
        "        df.to_csv(csv_path, index=False)\n",
        "\n",
        "\n",
        "# === Usage ===\n",
        "if __name__ == \"__main__\":\n",
        "    generator = FatigueDatasetGenerator(samples_per_case=300)\n",
        "    dataset_json, dataset_df = generator.generate_dataset()\n",
        "    generator.save(dataset_json, dataset_df,\n",
        "                   \"synthetic_fatigue_dataset.json\",\n",
        "                   \"synthetic_fatigue_dataset.csv\")\n",
        "    print(f\"✅ Dataset generated with {len(dataset_json)} samples.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7heOrDwew3WA",
        "outputId": "01c42394-4a71-476a-ce17-db132ba4d732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset generated with 2700 samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "3PK8-hztxFDM",
        "outputId": "993eb624-e631-4b08-a3a0-7eb478fedb70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ID                   timestamp  Blink Rate  Yawning Rate  PERCLOS   SDLP  \\\n",
              "0   1  2025-06-12T21:58:14.214482       12.48           0.0    14.01   6.89   \n",
              "1   2  2025-06-12T21:58:14.214542       12.28           0.0    12.45   0.15   \n",
              "2   3  2025-06-12T21:58:14.214565       12.59           0.0    13.84   5.55   \n",
              "3   4  2025-06-12T21:58:14.214586       13.76           0.0    10.08   9.02   \n",
              "4   5  2025-06-12T21:58:14.214610       10.96           0.0    14.85  14.51   \n",
              "\n",
              "   Steering Entropy  Lane Keeping Ratio  Lane Departure Frequency    SRR  \\\n",
              "0              0.86                0.24                      1.50  10.50   \n",
              "1              0.68                0.38                      0.50   1.98   \n",
              "2              0.45                0.22                      1.66   7.13   \n",
              "3              0.88                0.39                      0.64   2.62   \n",
              "4              0.71                0.56                      2.02  10.66   \n",
              "\n",
              "    SAV   CF   SF   LF  fan music vibration  \\\n",
              "0  1.90  Low  Low  Low  off   off       off   \n",
              "1  1.06  Low  Low  Low  off   off       off   \n",
              "2  3.12  Low  Low  Low  off   off       off   \n",
              "3  3.95  Low  Low  Low  off   off       off   \n",
              "4  3.12  Low  Low  Low  off   off       off   \n",
              "\n",
              "                                              reason  \n",
              "0  No signs of fatigue detected. No intervention ...  \n",
              "1  No signs of fatigue detected. No intervention ...  \n",
              "2  No signs of fatigue detected. No intervention ...  \n",
              "3  No signs of fatigue detected. No intervention ...  \n",
              "4  No signs of fatigue detected. No intervention ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df0bc0e6-e7bb-4160-b6cb-20766d32d15d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>Blink Rate</th>\n",
              "      <th>Yawning Rate</th>\n",
              "      <th>PERCLOS</th>\n",
              "      <th>SDLP</th>\n",
              "      <th>Steering Entropy</th>\n",
              "      <th>Lane Keeping Ratio</th>\n",
              "      <th>Lane Departure Frequency</th>\n",
              "      <th>SRR</th>\n",
              "      <th>SAV</th>\n",
              "      <th>CF</th>\n",
              "      <th>SF</th>\n",
              "      <th>LF</th>\n",
              "      <th>fan</th>\n",
              "      <th>music</th>\n",
              "      <th>vibration</th>\n",
              "      <th>reason</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2025-06-12T21:58:14.214482</td>\n",
              "      <td>12.48</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.01</td>\n",
              "      <td>6.89</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.24</td>\n",
              "      <td>1.50</td>\n",
              "      <td>10.50</td>\n",
              "      <td>1.90</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>off</td>\n",
              "      <td>off</td>\n",
              "      <td>off</td>\n",
              "      <td>No signs of fatigue detected. No intervention ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2025-06-12T21:58:14.214542</td>\n",
              "      <td>12.28</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.45</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.98</td>\n",
              "      <td>1.06</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>off</td>\n",
              "      <td>off</td>\n",
              "      <td>off</td>\n",
              "      <td>No signs of fatigue detected. No intervention ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2025-06-12T21:58:14.214565</td>\n",
              "      <td>12.59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.84</td>\n",
              "      <td>5.55</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.22</td>\n",
              "      <td>1.66</td>\n",
              "      <td>7.13</td>\n",
              "      <td>3.12</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>off</td>\n",
              "      <td>off</td>\n",
              "      <td>off</td>\n",
              "      <td>No signs of fatigue detected. No intervention ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2025-06-12T21:58:14.214586</td>\n",
              "      <td>13.76</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.08</td>\n",
              "      <td>9.02</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.64</td>\n",
              "      <td>2.62</td>\n",
              "      <td>3.95</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>off</td>\n",
              "      <td>off</td>\n",
              "      <td>off</td>\n",
              "      <td>No signs of fatigue detected. No intervention ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2025-06-12T21:58:14.214610</td>\n",
              "      <td>10.96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.85</td>\n",
              "      <td>14.51</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.56</td>\n",
              "      <td>2.02</td>\n",
              "      <td>10.66</td>\n",
              "      <td>3.12</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>Low</td>\n",
              "      <td>off</td>\n",
              "      <td>off</td>\n",
              "      <td>off</td>\n",
              "      <td>No signs of fatigue detected. No intervention ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df0bc0e6-e7bb-4160-b6cb-20766d32d15d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-df0bc0e6-e7bb-4160-b6cb-20766d32d15d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-df0bc0e6-e7bb-4160-b6cb-20766d32d15d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-53fe15ee-81fe-40cb-a403-b7f77bc54fbe\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-53fe15ee-81fe-40cb-a403-b7f77bc54fbe')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-53fe15ee-81fe-40cb-a403-b7f77bc54fbe button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset_df",
              "summary": "{\n  \"name\": \"dataset_df\",\n  \"rows\": 2700,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 779,\n        \"min\": 1,\n        \"max\": 2700,\n        \"num_unique_values\": 2700,\n        \"samples\": [\n          1340,\n          1223,\n          1107\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 2700,\n        \"samples\": [\n          \"2025-06-12T21:58:14.284533\",\n          \"2025-06-12T21:58:14.278356\",\n          \"2025-06-12T21:58:14.273130\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Blink Rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.277695983337722,\n        \"min\": 10.0,\n        \"max\": 30.0,\n        \"num_unique_values\": 1323,\n        \"samples\": [\n          21.9,\n          15.85,\n          10.94\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Yawning Rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5524542566654325,\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 285,\n        \"samples\": [\n          2.46,\n          2.43,\n          4.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PERCLOS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.548968279476032,\n        \"min\": 0.01,\n        \"max\": 60.0,\n        \"num_unique_values\": 2108,\n        \"samples\": [\n          58.91,\n          52.74,\n          27.47\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SDLP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.236457001545121,\n        \"min\": 0.03,\n        \"max\": 49.98,\n        \"num_unique_values\": 2094,\n        \"samples\": [\n          19.78,\n          47.9,\n          15.65\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Steering Entropy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5223355763074842,\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 495,\n        \"samples\": [\n          3.69,\n          0.62,\n          3.37\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lane Keeping Ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.270451873505113,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 101,\n        \"samples\": [\n          0.85,\n          0.26,\n          0.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lane Departure Frequency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5482826923858455,\n        \"min\": 0.0,\n        \"max\": 6.0,\n        \"num_unique_values\": 585,\n        \"samples\": [\n          5.29,\n          3.91,\n          0.82\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SRR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.768110385417174,\n        \"min\": 0.01,\n        \"max\": 35.0,\n        \"num_unique_values\": 1853,\n        \"samples\": [\n          6.31,\n          21.4,\n          33.38\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SAV\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.229735613179932,\n        \"min\": 1.0,\n        \"max\": 15.0,\n        \"num_unique_values\": 1052,\n        \"samples\": [\n          3.2,\n          6.08,\n          6.84\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CF\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Low\",\n          \"Moderate\",\n          \"High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SF\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Low\",\n          \"Moderate\",\n          \"High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LF\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Low\",\n          \"Moderate\",\n          \"High\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fan\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"off\",\n          \"level 2\",\n          \"level 3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"music\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"beep\",\n          \"off\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vibration\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Vibrate\",\n          \"off\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reason\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"High fatigue across systems impairs control. Full intervention improves driver responsiveness and safety.\",\n          \"Motor and lane variations suggest early fatigue. Moderate airflow stabilizes driver alertness.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load CSV dataset\n",
        "df = pd.read_csv(\"synthetic_fatigue_dataset.csv\")\n",
        "\n",
        "# Define features and targets\n",
        "feature_columns = [\n",
        "    \"Blink Rate\", \"Yawning Rate\", \"PERCLOS\", \"SDLP\", \"Steering Entropy\",\n",
        "    \"Lane Keeping Ratio\", \"Lane Departure Frequency\", \"SRR\", \"SAV\"\n",
        "]\n",
        "\n",
        "X = df[feature_columns]\n",
        "y_cf = df[\"CF\"]\n",
        "y_sf = df[\"SF\"]\n",
        "y_lf = df[\"LF\"]\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_cf_train, y_cf_test = train_test_split(X_scaled, y_cf, test_size=0.2, random_state=42)\n",
        "_, _, y_sf_train, y_sf_test = train_test_split(X_scaled, y_sf, test_size=0.2, random_state=42)\n",
        "_, _, y_lf_train, y_lf_test = train_test_split(X_scaled, y_lf, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train RandomForest classifiers\n",
        "clf_cf = RandomForestClassifier(random_state=42)\n",
        "clf_sf = RandomForestClassifier(random_state=42)\n",
        "clf_lf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "clf_cf.fit(X_train, y_cf_train)\n",
        "clf_sf.fit(X_train, y_sf_train)\n",
        "clf_lf.fit(X_train, y_lf_train)\n",
        "\n",
        "# Predict on test set\n",
        "cf_pred = clf_cf.predict(X_test)\n",
        "sf_pred = clf_sf.predict(X_test)\n",
        "lf_pred = clf_lf.predict(X_test)\n",
        "\n",
        "# Print classification reports\n",
        "print(\"=== Camera Fatigue (CF) Classification Report ===\")\n",
        "print(classification_report(y_cf_test, cf_pred))\n",
        "print(\"\\n=== Steering Fatigue (SF) Classification Report ===\")\n",
        "print(classification_report(y_sf_test, sf_pred))\n",
        "print(\"\\n=== Lane Fatigue (LF) Classification Report ===\")\n",
        "print(classification_report(y_lf_test, lf_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGZ2PH0mxjpu",
        "outputId": "083f4aca-1f12-4f15-fd21-a64a61f4a12e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Camera Fatigue (CF) Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       1.00      1.00      1.00       187\n",
            "         Low       1.00      1.00      1.00       190\n",
            "    Moderate       1.00      1.00      1.00       163\n",
            "\n",
            "    accuracy                           1.00       540\n",
            "   macro avg       1.00      1.00      1.00       540\n",
            "weighted avg       1.00      1.00      1.00       540\n",
            "\n",
            "\n",
            "=== Steering Fatigue (SF) Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       1.00      1.00      1.00       176\n",
            "         Low       1.00      1.00      1.00       187\n",
            "    Moderate       1.00      1.00      1.00       177\n",
            "\n",
            "    accuracy                           1.00       540\n",
            "   macro avg       1.00      1.00      1.00       540\n",
            "weighted avg       1.00      1.00      1.00       540\n",
            "\n",
            "\n",
            "=== Lane Fatigue (LF) Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       1.00      1.00      1.00       176\n",
            "         Low       1.00      1.00      1.00       187\n",
            "    Moderate       1.00      1.00      1.00       177\n",
            "\n",
            "    accuracy                           1.00       540\n",
            "   macro avg       1.00      1.00      1.00       540\n",
            "weighted avg       1.00      1.00      1.00       540\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt Template Generator"
      ],
      "metadata": {
        "id": "yFBVvs_D3VfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt(row):\n",
        "    fatigue_section = (\n",
        "        f\"Fatigue Levels:\\n\"\n",
        "        f\"  - Camera Fatigue: {row['CF']}\\n\"\n",
        "        f\"  - Steering Fatigue: {row['SF']}\\n\"\n",
        "        f\"  - Lane Fatigue: {row['LF']}\\n\"\n",
        "    )\n",
        "\n",
        "    feature_section = \"Features:\\n\" + \"\\n\".join([\n",
        "        f\"  - {feat}: {row[feat]}\" for feat in [\n",
        "            \"Blink Rate\", \"Yawning Rate\", \"PERCLOS\", \"SDLP\", \"Steering Entropy\",\n",
        "            \"Lane Keeping Ratio\", \"Lane Departure Frequency\", \"SRR\", \"SAV\"\n",
        "        ]\n",
        "    ])\n",
        "\n",
        "    assistant_output = (\n",
        "        f\"Intervention:\\n\"\n",
        "        f\"  - Fan: {row['fan']}\\n\"\n",
        "        f\"  - Music: {row['music']}\\n\"\n",
        "        f\"  - Vibration: {row['vibration']}\\n\"\n",
        "        f\"Reason: {row['reason']}\"\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are an intelligent fatigue mitigation assistant. Analyze fatigue levels and sensor features to suggest driver interventions.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"{fatigue_section}\\n{feature_section}\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": assistant_output\n",
        "            }\n",
        "        ]\n",
        "    }\n"
      ],
      "metadata": {
        "id": "N3qCbaqE3WJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save to JSONL for Fine-Tuning"
      ],
      "metadata": {
        "id": "49ogHXdp3dtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Assuming `df` is your DataFrame\n",
        "with open(\"llm_fatigue_prompt_data.jsonl\", \"w\") as out_file:\n",
        "    for _, row in df.iterrows():\n",
        "        prompt_example = generate_prompt(row)\n",
        "        out_file.write(json.dumps(prompt_example) + \"\\n\")\n"
      ],
      "metadata": {
        "id": "YnLaOugb3eKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Few-Shot LLM Evaluator Script (OpenAI or Huggingface Transformers)"
      ],
      "metadata": {
        "id": "AFfDIIon5K5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig\n",
        "import torch\n",
        "import random\n",
        "\n",
        "# === SETTINGS ===\n",
        "model_id = \"meta-llama/Llama-2-7b-hf\"\n",
        "hf_token = \"hf_hExLoiMKvZTzLKJxesZbzIPWTshlSGaCj\" # Replace with your actual Hugging Face token\n",
        "max_new_tokens = 150\n",
        "num_fewshot = 3\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# === LOAD DATASET ===\n",
        "df = pd.read_csv(\"synthetic_fatigue_dataset.csv\")\n",
        "feature_cols = [\n",
        "    \"Blink Rate\", \"Yawning Rate\", \"PERCLOS\", \"SDLP\", \"Steering Entropy\",\n",
        "    \"Lane Keeping Ratio\", \"Lane Departure Frequency\", \"SRR\", \"SAV\"\n",
        "]\n",
        "\n",
        "# === PROMPT HELPERS ===\n",
        "def format_instance(row):\n",
        "    fatigue_info = (\n",
        "        f\"Camera Fatigue: {row['CF']}\\n\"\n",
        "        f\"Steering Fatigue: {row['SF']}\\n\"\n",
        "        f\"Lane Fatigue: {row['LF']}\\n\"\n",
        "    )\n",
        "    features = \"\\n\".join([f\"{col}: {row[col]}\" for col in feature_cols])\n",
        "    answer = (\n",
        "        f\"Fan: {row['fan']}\\n\"\n",
        "        f\"Music: {row['music']}\\n\"\n",
        "        f\"Vibration: {row['vibration']}\\n\"\n",
        "        f\"Reason: {row['reason']}\"\n",
        "    )\n",
        "    return fatigue_info + features, answer\n",
        "\n",
        "def build_fewshot_prompt(df, test_row):\n",
        "    fewshots = df.sample(num_fewshot)\n",
        "    prompt = \"You are an AI fatigue assistant. Based on fatigue levels and sensor features, suggest an appropriate intervention and explain the reason.\\n\\n\"\n",
        "\n",
        "    for _, row in fewshots.iterrows():\n",
        "        user, answer = format_instance(row)\n",
        "        prompt += f\"User:\\n{user}\\nAssistant:\\n{answer}\\n---\\n\"\n",
        "\n",
        "    test_input, _ = format_instance(test_row)\n",
        "    prompt += f\"User:\\n{test_input}\\nAssistant:\\n\"\n",
        "    return prompt\n",
        "\n",
        "# === LOAD MODEL AND TOKENIZER ===\n",
        "print(\"🔄 Loading model...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=hf_token)\n",
        "\n",
        "# Configure 8-bit loading\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_8bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_auth_token=hf_token,\n",
        "    quantization_config=quantization_config # Add quantization config\n",
        ")\n",
        "\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# === RUN INFERENCE ===\n",
        "test_row = df.sample(1).iloc[0]\n",
        "prompt = build_fewshot_prompt(df, test_row)\n",
        "\n",
        "print(\"\\n🧠 Prompt sent to model:\\n\")\n",
        "print(prompt)\n",
        "\n",
        "print(\"\\n🧾 Generating response...\\n\")\n",
        "output = pipe(prompt, max_new_tokens=max_new_tokens, do_sample=False)[0][\"generated_text\"]\n",
        "\n",
        "print(\"✅ LLM Response:\\n\")\n",
        "print(output[len(prompt):].strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "da72fe855c6a43209b54e641a415ca64",
            "22d0e3f178bc4ce7a7197fa4841e29ce",
            "67170c8edf6f40d4a0bb33b85c0e61af",
            "390d7e8216274761aba0a1fa8e0c11b7",
            "7ed43c4fd189478b9a8b5ba3a11b3899",
            "81a3113086854accbc8138a47d7cfcba",
            "8fdd41233a2b4482a436aae7cc6ed246",
            "bd2b274d64754acbb38cca84d6218a2f",
            "cfa62da674534409bfa6a17d978bd1a1",
            "e066452acde04c3ea4173d47ce8250c8",
            "ebd241a51e524fe1af07f784f1a334ca"
          ]
        },
        "id": "auVMGASs5Hq8",
        "outputId": "bdff8f60-c1db-4bd4-b545-cc2f789eef60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Loading model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py:902: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da72fe855c6a43209b54e641a415ca64"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🧠 Prompt sent to model:\n",
            "\n",
            "You are an AI fatigue assistant. Based on fatigue levels and sensor features, suggest an appropriate intervention and explain the reason.\n",
            "\n",
            "User:\n",
            "Camera Fatigue: Moderate\n",
            "Steering Fatigue: High\n",
            "Lane Fatigue: High\n",
            "Blink Rate: 16.24\n",
            "Yawning Rate: 1.0\n",
            "PERCLOS: 26.71\n",
            "SDLP: 41.11\n",
            "Steering Entropy: 4.47\n",
            "Lane Keeping Ratio: 0.98\n",
            "Lane Departure Frequency: 3.94\n",
            "SRR: 25.13\n",
            "SAV: 14.39\n",
            "Assistant:\n",
            "Fan: level 3\n",
            "Music: beep\n",
            "Vibration: Vibrate\n",
            "Reason: Motor and lane fatigue with visual strain detected. Strong multi-sensory cues are required immediately.\n",
            "---\n",
            "User:\n",
            "Camera Fatigue: Low\n",
            "Steering Fatigue: Moderate\n",
            "Lane Fatigue: Moderate\n",
            "Blink Rate: 11.91\n",
            "Yawning Rate: 0.0\n",
            "PERCLOS: 5.04\n",
            "SDLP: 34.57\n",
            "Steering Entropy: 2.07\n",
            "Lane Keeping Ratio: 0.77\n",
            "Lane Departure Frequency: 2.58\n",
            "SRR: 23.26\n",
            "SAV: 7.46\n",
            "Assistant:\n",
            "Fan: level 2\n",
            "Music: off\n",
            "Vibration: off\n",
            "Reason: Motor and lane variations suggest early fatigue. Moderate airflow stabilizes driver alertness.\n",
            "---\n",
            "User:\n",
            "Camera Fatigue: High\n",
            "Steering Fatigue: Low\n",
            "Lane Fatigue: Low\n",
            "Blink Rate: 18.74\n",
            "Yawning Rate: 2.86\n",
            "PERCLOS: 59.8\n",
            "SDLP: 17.69\n",
            "Steering Entropy: 0.37\n",
            "Lane Keeping Ratio: 0.31\n",
            "Lane Departure Frequency: 0.21\n",
            "SRR: 5.04\n",
            "SAV: 3.97\n",
            "Assistant:\n",
            "Fan: level 3\n",
            "Music: beep\n",
            "Vibration: Vibrate\n",
            "Reason: Severe visual fatigue threatens awareness. Multi-modal alerts counter visual disengagement effectively.\n",
            "---\n",
            "User:\n",
            "Camera Fatigue: Low\n",
            "Steering Fatigue: High\n",
            "Lane Fatigue: High\n",
            "Blink Rate: 14.13\n",
            "Yawning Rate: 0.0\n",
            "PERCLOS: 8.63\n",
            "SDLP: 48.88\n",
            "Steering Entropy: 4.12\n",
            "Lane Keeping Ratio: 0.86\n",
            "Lane Departure Frequency: 5.44\n",
            "SRR: 28.36\n",
            "SAV: 12.62\n",
            "Assistant:\n",
            "\n",
            "\n",
            "🧾 Generating response...\n",
            "\n",
            "✅ LLM Response:\n",
            "\n",
            "Fan: level 2\n",
            "Music: off\n",
            "Vibration: off\n",
            "Reason: Motor and lane variations suggest early fatigue. Moderate airflow stabilizes driver alertness.\n",
            "---\n",
            "User:\n",
            "Camera Fatigue: Moderate\n",
            "Steering Fatigue: Moderate\n",
            "Lane Fatigue: Moderate\n",
            "Blink Rate: 14.13\n",
            "Yawning Rate: 0.0\n",
            "PERCLOS: 10.02\n",
            "SDLP: 34.57\n",
            "Steering Entropy: 2.07\n",
            "Lane Keeping Ratio: 0.77\n",
            "Lane Departure Frequency:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch Evaluation with Scoring"
      ],
      "metadata": {
        "id": "ILl2oZukL8U5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# === FUNCTION: Extract predictions from raw LLM text ===\n",
        "def extract_prediction(raw_response: str) -> dict:\n",
        "    \"\"\"\n",
        "    Extract fan/music/vibration prediction from raw LLM response text.\n",
        "    \"\"\"\n",
        "    prediction = {\n",
        "        \"fan\": \"unknown\",\n",
        "        \"music\": \"unknown\",\n",
        "        \"vibration\": \"unknown\"\n",
        "    }\n",
        "\n",
        "    fan_match = re.search(r\"Fan\\s*[:\\-]\\s*(level \\d|off)\", raw_response, re.IGNORECASE)\n",
        "    music_match = re.search(r\"Music\\s*[:\\-]\\s*(beep|off)\", raw_response, re.IGNORECASE)\n",
        "    vib_match = re.search(r\"Vibration\\s*[:\\-]\\s*(Vibrate|off)\", raw_response, re.IGNORECASE)\n",
        "\n",
        "    if fan_match: prediction[\"fan\"] = fan_match.group(1).lower()\n",
        "    if music_match: prediction[\"music\"] = music_match.group(1).lower()\n",
        "    if vib_match: prediction[\"vibration\"] = vib_match.group(1).capitalize()\n",
        "\n",
        "    return prediction\n",
        "\n",
        "# === FUNCTION: Evaluate multiple test samples ===\n",
        "def evaluate_llm_batch(df, num_samples=20):\n",
        "    results = []\n",
        "    test_rows = df.sample(num_samples, random_state=42)\n",
        "\n",
        "    for idx, (_, test_row) in enumerate(test_rows.iterrows()):\n",
        "        prompt = build_fewshot_prompt(df, test_row)\n",
        "        print(f\"\\n🔄 [{idx+1}/{num_samples}] Running prompt...\")\n",
        "        try:\n",
        "            output = pipe(prompt, max_new_tokens=max_new_tokens, do_sample=False)[0][\"generated_text\"]\n",
        "            model_output = output[len(prompt):].strip()\n",
        "            prediction = extract_prediction(model_output)\n",
        "\n",
        "            results.append({\n",
        "                \"id\": test_row[\"ID\"],\n",
        "                \"ground_fan\": test_row[\"fan\"].lower(),\n",
        "                \"ground_music\": test_row[\"music\"].lower(),\n",
        "                \"ground_vibration\": test_row[\"vibration\"].capitalize(),\n",
        "                \"pred_fan\": prediction[\"fan\"],\n",
        "                \"pred_music\": prediction[\"music\"],\n",
        "                \"pred_vibration\": prediction[\"vibration\"],\n",
        "                \"match_fan\": prediction[\"fan\"] == test_row[\"fan\"].lower(),\n",
        "                \"match_music\": prediction[\"music\"] == test_row[\"music\"].lower(),\n",
        "                \"match_vibration\": prediction[\"vibration\"] == test_row[\"vibration\"].capitalize()\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error: {e}\")\n",
        "            continue\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# === RUN BATCH EVALUATION ===\n",
        "batch_df = evaluate_llm_batch(df, num_samples=20)\n",
        "\n",
        "# === DISPLAY EVALUATION SUMMARY ===\n",
        "fan_acc = accuracy_score(batch_df[\"ground_fan\"], batch_df[\"pred_fan\"])\n",
        "music_acc = accuracy_score(batch_df[\"ground_music\"], batch_df[\"pred_music\"])\n",
        "vibration_acc = accuracy_score(batch_df[\"ground_vibration\"], batch_df[\"pred_vibration\"])\n",
        "\n",
        "print(\"\\n=== 🎯 Accuracy Report (LLM vs Ground Truth) ===\")\n",
        "print(f\"Fan       Accuracy: {fan_acc * 100:.2f}%\")\n",
        "print(f\"Music     Accuracy: {music_acc * 100:.2f}%\")\n",
        "print(f\"Vibration Accuracy: {vibration_acc * 100:.2f}%\")\n",
        "\n",
        "# Optional: See full results\n",
        "batch_df[[\"id\", \"ground_fan\", \"pred_fan\", \"ground_music\", \"pred_music\", \"ground_vibration\", \"pred_vibration\"]]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GQ-iPKrBOHGJ",
        "outputId": "b86b43b5-c58a-425e-a9a2-a03eecfb053c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 [1/20] Running prompt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 [2/20] Running prompt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 [3/20] Running prompt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 [4/20] Running prompt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 [5/20] Running prompt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 [6/20] Running prompt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 [7/20] Running prompt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 [8/20] Running prompt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 [9/20] Running prompt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 [10/20] Running prompt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 [11/20] Running prompt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 [12/20] Running prompt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 [13/20] Running prompt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 [14/20] Running prompt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 [15/20] Running prompt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 [16/20] Running prompt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 [17/20] Running prompt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 [18/20] Running prompt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 [19/20] Running prompt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 [20/20] Running prompt...\n",
            "\n",
            "=== 🎯 Accuracy Report (LLM vs Ground Truth) ===\n",
            "Fan       Accuracy: 55.00%\n",
            "Music     Accuracy: 65.00%\n",
            "Vibration Accuracy: 55.00%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id ground_fan pred_fan ground_music pred_music ground_vibration  \\\n",
              "0   1340    level 2  level 4         beep       beep              Off   \n",
              "1   1223    level 2  level 3         beep       beep              Off   \n",
              "2   1107    level 2  level 2          off        off              Off   \n",
              "3    813    level 3  level 2         beep        off          Vibrate   \n",
              "4   1232    level 2  level 2         beep        off              Off   \n",
              "5    566    level 2  level 1          off       beep              Off   \n",
              "6    846    level 3      off         beep        off          Vibrate   \n",
              "7   1005    level 2  level 2          off        off              Off   \n",
              "8   2284    level 3  level 3         beep        off          Vibrate   \n",
              "9    701    level 3  level 1         beep       beep          Vibrate   \n",
              "10  1504    level 3  level 3         beep        off          Vibrate   \n",
              "11   529    level 2  level 1          off        off              Off   \n",
              "12  2290    level 3  level 3         beep       beep          Vibrate   \n",
              "13  1054    level 2  level 2          off        off              Off   \n",
              "14  2411    level 3  level 3         beep       beep          Vibrate   \n",
              "15  1124    level 2  level 3          off       beep              Off   \n",
              "16   882    level 3  level 3         beep       beep          Vibrate   \n",
              "17  2665    level 3  level 3         beep       beep          Vibrate   \n",
              "18   943    level 2  level 2          off        off              Off   \n",
              "19   870    level 3  level 1         beep       beep          Vibrate   \n",
              "\n",
              "   pred_vibration  \n",
              "0         Vibrate  \n",
              "1         Vibrate  \n",
              "2             Off  \n",
              "3             Off  \n",
              "4             Off  \n",
              "5             Off  \n",
              "6             Off  \n",
              "7             Off  \n",
              "8             Off  \n",
              "9             Off  \n",
              "10            Off  \n",
              "11            Off  \n",
              "12        Vibrate  \n",
              "13            Off  \n",
              "14        Vibrate  \n",
              "15        Vibrate  \n",
              "16        Vibrate  \n",
              "17        Vibrate  \n",
              "18            Off  \n",
              "19            Off  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17091de2-8e15-4d3b-95d5-4a52d12a3f17\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>ground_fan</th>\n",
              "      <th>pred_fan</th>\n",
              "      <th>ground_music</th>\n",
              "      <th>pred_music</th>\n",
              "      <th>ground_vibration</th>\n",
              "      <th>pred_vibration</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1340</td>\n",
              "      <td>level 2</td>\n",
              "      <td>level 4</td>\n",
              "      <td>beep</td>\n",
              "      <td>beep</td>\n",
              "      <td>Off</td>\n",
              "      <td>Vibrate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1223</td>\n",
              "      <td>level 2</td>\n",
              "      <td>level 3</td>\n",
              "      <td>beep</td>\n",
              "      <td>beep</td>\n",
              "      <td>Off</td>\n",
              "      <td>Vibrate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1107</td>\n",
              "      <td>level 2</td>\n",
              "      <td>level 2</td>\n",
              "      <td>off</td>\n",
              "      <td>off</td>\n",
              "      <td>Off</td>\n",
              "      <td>Off</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>813</td>\n",
              "      <td>level 3</td>\n",
              "      <td>level 2</td>\n",
              "      <td>beep</td>\n",
              "      <td>off</td>\n",
              "      <td>Vibrate</td>\n",
              "      <td>Off</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1232</td>\n",
              "      <td>level 2</td>\n",
              "      <td>level 2</td>\n",
              "      <td>beep</td>\n",
              "      <td>off</td>\n",
              "      <td>Off</td>\n",
              "      <td>Off</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>566</td>\n",
              "      <td>level 2</td>\n",
              "      <td>level 1</td>\n",
              "      <td>off</td>\n",
              "      <td>beep</td>\n",
              "      <td>Off</td>\n",
              "      <td>Off</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>846</td>\n",
              "      <td>level 3</td>\n",
              "      <td>off</td>\n",
              "      <td>beep</td>\n",
              "      <td>off</td>\n",
              "      <td>Vibrate</td>\n",
              "      <td>Off</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1005</td>\n",
              "      <td>level 2</td>\n",
              "      <td>level 2</td>\n",
              "      <td>off</td>\n",
              "      <td>off</td>\n",
              "      <td>Off</td>\n",
              "      <td>Off</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2284</td>\n",
              "      <td>level 3</td>\n",
              "      <td>level 3</td>\n",
              "      <td>beep</td>\n",
              "      <td>off</td>\n",
              "      <td>Vibrate</td>\n",
              "      <td>Off</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>701</td>\n",
              "      <td>level 3</td>\n",
              "      <td>level 1</td>\n",
              "      <td>beep</td>\n",
              "      <td>beep</td>\n",
              "      <td>Vibrate</td>\n",
              "      <td>Off</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1504</td>\n",
              "      <td>level 3</td>\n",
              "      <td>level 3</td>\n",
              "      <td>beep</td>\n",
              "      <td>off</td>\n",
              "      <td>Vibrate</td>\n",
              "      <td>Off</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>529</td>\n",
              "      <td>level 2</td>\n",
              "      <td>level 1</td>\n",
              "      <td>off</td>\n",
              "      <td>off</td>\n",
              "      <td>Off</td>\n",
              "      <td>Off</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2290</td>\n",
              "      <td>level 3</td>\n",
              "      <td>level 3</td>\n",
              "      <td>beep</td>\n",
              "      <td>beep</td>\n",
              "      <td>Vibrate</td>\n",
              "      <td>Vibrate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1054</td>\n",
              "      <td>level 2</td>\n",
              "      <td>level 2</td>\n",
              "      <td>off</td>\n",
              "      <td>off</td>\n",
              "      <td>Off</td>\n",
              "      <td>Off</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2411</td>\n",
              "      <td>level 3</td>\n",
              "      <td>level 3</td>\n",
              "      <td>beep</td>\n",
              "      <td>beep</td>\n",
              "      <td>Vibrate</td>\n",
              "      <td>Vibrate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1124</td>\n",
              "      <td>level 2</td>\n",
              "      <td>level 3</td>\n",
              "      <td>off</td>\n",
              "      <td>beep</td>\n",
              "      <td>Off</td>\n",
              "      <td>Vibrate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>882</td>\n",
              "      <td>level 3</td>\n",
              "      <td>level 3</td>\n",
              "      <td>beep</td>\n",
              "      <td>beep</td>\n",
              "      <td>Vibrate</td>\n",
              "      <td>Vibrate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2665</td>\n",
              "      <td>level 3</td>\n",
              "      <td>level 3</td>\n",
              "      <td>beep</td>\n",
              "      <td>beep</td>\n",
              "      <td>Vibrate</td>\n",
              "      <td>Vibrate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>943</td>\n",
              "      <td>level 2</td>\n",
              "      <td>level 2</td>\n",
              "      <td>off</td>\n",
              "      <td>off</td>\n",
              "      <td>Off</td>\n",
              "      <td>Off</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>870</td>\n",
              "      <td>level 3</td>\n",
              "      <td>level 1</td>\n",
              "      <td>beep</td>\n",
              "      <td>beep</td>\n",
              "      <td>Vibrate</td>\n",
              "      <td>Off</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17091de2-8e15-4d3b-95d5-4a52d12a3f17')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-17091de2-8e15-4d3b-95d5-4a52d12a3f17 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-17091de2-8e15-4d3b-95d5-4a52d12a3f17');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b2401669-cdbb-4415-a59a-e245d878b446\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b2401669-cdbb-4415-a59a-e245d878b446')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b2401669-cdbb-4415-a59a-e245d878b446 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"batch_df[[\\\"id\\\", \\\"ground_fan\\\", \\\"pred_fan\\\", \\\"ground_music\\\", \\\"pred_music\\\", \\\"ground_vibration\\\", \\\"pred_vibration\\\"]]\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 637,\n        \"min\": 529,\n        \"max\": 2665,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          1340,\n          2665,\n          1124\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_fan\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"level 3\",\n          \"level 2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_fan\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"level 3\",\n          \"off\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_music\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"off\",\n          \"beep\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_music\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"off\",\n          \"beep\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_vibration\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Vibrate\",\n          \"Off\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_vibration\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Off\",\n          \"Vibrate\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINE-TUNING LLaMA IN 3 PHASES"
      ],
      "metadata": {
        "id": "CbHAS7maTbMp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PHASE 1: Generate Fine-Tuning Data"
      ],
      "metadata": {
        "id": "eGx3hsopTep1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Load your synthetic dataset\n",
        "df = pd.read_csv(\"synthetic_fatigue_dataset.csv\")\n",
        "\n",
        "# Feature columns used in prompts\n",
        "feature_cols = [\n",
        "    \"Blink Rate\", \"Yawning Rate\", \"PERCLOS\", \"SDLP\", \"Steering Entropy\",\n",
        "    \"Lane Keeping Ratio\", \"Lane Departure Frequency\", \"SRR\", \"SAV\"\n",
        "]\n",
        "\n",
        "# Format: User & Assistant Text\n",
        "def format_chat_instance(row):\n",
        "    fatigue_info = (\n",
        "        f\"Camera Fatigue: {row['CF']}\\n\"\n",
        "        f\"Steering Fatigue: {row['SF']}\\n\"\n",
        "        f\"Lane Fatigue: {row['LF']}\\n\"\n",
        "    )\n",
        "    features = \"\\n\".join([f\"{col}: {row[col]}\" for col in feature_cols])\n",
        "    input_text = fatigue_info + features\n",
        "\n",
        "    output_text = (\n",
        "        f\"Fan: {row['fan']}\\n\"\n",
        "        f\"Music: {row['music']}\\n\"\n",
        "        f\"Vibration: {row['vibration']}\\n\"\n",
        "        f\"Reason: {row['reason']}\"\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are an AI fatigue assistant. Based on fatigue levels and sensor features, decide appropriate intervention and explain why.\"},\n",
        "            {\"role\": \"user\", \"content\": input_text},\n",
        "            {\"role\": \"assistant\", \"content\": output_text}\n",
        "        ]\n",
        "    }\n",
        "\n",
        "# Sample 1000 rows for training\n",
        "sampled_df = df.sample(1000, random_state=42)\n",
        "\n",
        "# Save as JSONL\n",
        "with open(\"llama_finetune_data.jsonl\", \"w\") as f:\n",
        "    for _, row in sampled_df.iterrows():\n",
        "        sample = format_chat_instance(row)\n",
        "        f.write(json.dumps(sample) + \"\\n\")\n",
        "\n",
        "print(\"✅ Phase 1 Complete: Generated llama_finetune_data.jsonl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uXXaWrUTcdB",
        "outputId": "51f78491-eed4-45da-c77f-b7c8a6d12567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Phase 1 Complete: Generated llama_finetune_data.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def generate_finetune_prompt(row):\n",
        "    user_input, assistant_output = format_instance(row)\n",
        "    return {\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are an AI fatigue assistant. Based on fatigue levels and features, decide interventions and explain why.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": user_input\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"assistant\",\n",
        "                \"content\": assistant_output\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "# Save to JSONL (e.g. 1000 samples)\n",
        "subset = df.sample(n=1000, random_state=42)\n",
        "\n",
        "with open(\"llama_finetune_data.jsonl\", \"w\") as f:\n",
        "    for _, row in subset.iterrows():\n",
        "        example = generate_finetune_prompt(row)\n",
        "        f.write(json.dumps(example) + \"\\n\")\n",
        "\n",
        "print(\"✅ Prompt training data saved as llama_finetune_data.jsonl\")\n"
      ],
      "metadata": {
        "id": "fSkXs2r9U1Pp",
        "outputId": "13e341dc-9dbb-4222-969d-ee363f54ad0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Prompt training data saved as llama_finetune_data.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PHASE 2: Fine-Tune LLaMA 7B with LoRA (Lightweight Training)"
      ],
      "metadata": {
        "id": "9jAvCFsgTlD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n",
        "from datasets import load_dataset\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "import torch\n",
        "\n",
        "model_id = \"meta-llama/Llama-2-7b-hf\"\n",
        "hf_token = \"hf_hExLoiMKvZTzLKJxesZbzIPWTshlSGaCj\"\n",
        "\n",
        "# Load model + tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_auth_token=hf_token\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=hf_token)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Load training data\n",
        "# Modified to explicitly load from local json file\n",
        "dataset = load_dataset(\"json\", data_files=\"llama_finetune_data.jsonl\")\n",
        "\n",
        "# Tokenize messages\n",
        "def tokenize_fn(example):\n",
        "    # Ensure the input is a list of messages\n",
        "    if isinstance(example[\"messages\"], list):\n",
        "        return tokenizer.apply_chat_template(example[\"messages\"], return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512)\n",
        "    else:\n",
        "        # Handle cases where 'messages' might not be a list, or log a warning\n",
        "        print(f\"Warning: 'messages' field is not a list in example: {example}\")\n",
        "        return {\"input_ids\": [], \"attention_mask\": []} # Return empty tensors or handle appropriately\n",
        "\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_fn, batched=True)\n",
        "\n",
        "\n",
        "# Define LoRA config\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        ")\n",
        "\n",
        "# Inject LoRA into model\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "# Training setup\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./llama-fatigue-finetune\",\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=2,\n",
        "    learning_rate=2e-4,\n",
        "    num_train_epochs=3,\n",
        "    logging_dir=\"./logs\",\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=True\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Train!\n",
        "trainer.train()\n",
        "print(\"✅ Phase 2 Complete: Model fine-tuned with LoRA\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598,
          "referenced_widgets": [
            "801d21c7454246c09e846e264699293d",
            "e872b7ff07dd484ca97328d0c9955184",
            "b5e62c48ae6442528124af5a245df508",
            "f917ab90728f4822be54446a6c7135f7",
            "8a996455481642c4999ea995e8329be2",
            "22fdf4933a8b40c1829d2e53ae1e11b8",
            "3941f692eb684d08ae71ddf7252f75e5",
            "dfa4ea7264924765965583c93f470259",
            "d1bd478563ef4333a9cd9b63ae0505aa",
            "697c40dfdbe647fba93ffe676d760c3f",
            "6849abaf9fac4b27be2147e89383f00e"
          ]
        },
        "id": "78LKlCkETliQ",
        "outputId": "15acf883-e298-436f-ebb3-c90c228ebd67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "801d21c7454246c09e846e264699293d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 72.12 MiB is free. Process 73021 has 14.67 GiB memory in use. Of the allocated memory 13.97 GiB is allocated by PyTorch, and 578.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-2009262055>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Load model + tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m                 \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    572\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mold_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4572\u001b[0m                 \u001b[0moffload_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4573\u001b[0m                 \u001b[0merror_msgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4574\u001b[0;31m             \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4575\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4576\u001b[0m                 \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[1;32m   5029\u001b[0m             \u001b[0;31m# Skip it with fsdp on ranks other than 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5030\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_fsdp_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_local_dist_rank_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_quantized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5031\u001b[0;31m                 disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(\n\u001b[0m\u001b[1;32m   5032\u001b[0m                     \u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5033\u001b[0m                     \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, shard_file, expected_keys, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, cpu_offload_folder, cpu_offload_index, hf_quantizer, is_safetensors, keep_in_fp32_regex, unexpected_keys, device_mesh)\u001b[0m\n\u001b[1;32m    841\u001b[0m                     \u001b[0mparam_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_local_dist_rank_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"meta\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m                 \u001b[0m_load_parameter_into_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 250.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 72.12 MiB is free. Process 73021 has 14.67 GiB memory in use. Of the allocated memory 13.97 GiB is allocated by PyTorch, and 578.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer, AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "\n",
        "# ⛔ DO NOT reload model or tokenizer — you already did it in the earlier cell\n",
        "\n",
        "# Reload tokenizer just for safety if needed (skip if already available)\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=hf_token)\n",
        "\n",
        "# Load dataset from JSONL\n",
        "dataset = load_dataset(\"json\", data_files=\"llama_finetune_data.jsonl\")\n",
        "\n",
        "# Tokenize with chat template\n",
        "def tokenize(sample):\n",
        "    return tokenizer.apply_chat_template(\n",
        "        sample[\"messages\"], return_tensors=\"pt\", padding=\"max_length\",\n",
        "        truncation=True, max_length=512\n",
        "    )\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize)\n",
        "\n",
        "# Setup LoRA config\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.CAUSAL_LM\n",
        ")\n",
        "\n",
        "# Add LoRA adapters to the already-loaded model\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "# Training args\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./llama-fatigue-finetuned\",\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=2,\n",
        "    learning_rate=2e-4,\n",
        "    num_train_epochs=3,\n",
        "    fp16=True,\n",
        "    logging_dir=\"./logs\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Setup Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    args=training_args\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "Va10RmhTU53x",
        "outputId": "82b1d976-9b1a-4506-88fd-69fb04bd378e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498,
          "referenced_widgets": [
            "d2dfb76546744b809d781d4f31dee7c7",
            "932f399705a3472a9c7721f3fc88dfb9",
            "b408a1baf6424c669ca099fb3ae0b94b",
            "9821a6c57bed4182924891b6949debe8",
            "b3f4f561c2544e59843747bccc973668",
            "2d97fcf6368b47fc900d62397a179dff",
            "70bb3c7580684990adf0295c188da7a4",
            "f44ac9c12c2e487d8296797bd5ea6871",
            "7c18249877dd4a5eb9f979915bb2189a",
            "69c2b44e98a64b0baf07414ba74aeb80",
            "89b220b66ebf40629e4b3bd7a29341c3",
            "769107a5a6b741918915bab7e1a96ec0",
            "8e3032a49bbe42b0b6439686582e6adf",
            "167122d29fbb411093844cd41531db71",
            "99df95928b6847ef89b2737c8c83282d",
            "a2b46ea30f6c4e21b4edb5db2bc72d25",
            "2e66ad210de14c518638e83f7bdc8bf3",
            "9d90bba482644783a07d6271a7012f03",
            "c063ef7920564637855fe800af2efd44",
            "ed8b8e688f1644bba906e68270ceb16a",
            "54ffc0a131da4cefaaca9e44a00c3da0",
            "dc12266d7f544a0ca2fbde49e689838c",
            "8a698f236f5e444db312a34f7cfde112",
            "4c1b1eaac80d47a8bbdc0a26960662e6",
            "db77b0d5e039440a8a16856a8eba85a9",
            "69df5c341fd64a36a64fb03450902308",
            "71f426aef3a7488787b64056cb12c091",
            "50bde8b4303d4756908316e5876b600f",
            "c20dda6ef1de477b9e7646ce98fab41f",
            "b43dd01294274cdbba1a4faa519ee6f9",
            "449cfcf1a35443d5b39103962913a371",
            "67184b881bbe47e4aed2a465a4633fda",
            "e9a66ca4510f48ad9146874a0d7145da"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2dfb76546744b809d781d4f31dee7c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "769107a5a6b741918915bab7e1a96ec0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a698f236f5e444db312a34f7cfde112"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "Loading a dataset cached in a LocalFileSystem is not supported.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-110863027>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Load dataset from JSONL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"llama_finetune_data.jsonl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Tokenize with chat template\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         \u001b[0mkeep_in_memory\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeep_in_memory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mis_small_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilder_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m     )\n\u001b[0;32m-> 2149\u001b[0;31m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverification_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverification_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_in_memory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2150\u001b[0m     \u001b[0;31m# Rename and cast features to match task schema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/builder.py\u001b[0m in \u001b[0;36mas_dataset\u001b[0;34m(self, split, run_post_process, verification_mode, ignore_verifications, in_memory)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0mis_local\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_remote_filesystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_local\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loading a dataset cached in a {type(self._fs).__name__} is not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m             raise FileNotFoundError(\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Loading a dataset cached in a LocalFileSystem is not supported."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PHASE 3: Run Inference Using Fine-Tuned Model"
      ],
      "metadata": {
        "id": "uILpuhh1TxFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load tokenizer and fine-tuned model\n",
        "model_dir = \"./llama-fatigue-finetune\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_dir)\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# Create test prompt (example)\n",
        "prompt = \"\"\"User:\n",
        "Camera Fatigue: High\n",
        "Steering Fatigue: Moderate\n",
        "Lane Fatigue: Moderate\n",
        "Blink Rate: 25.6\n",
        "Yawning Rate: 3\n",
        "PERCLOS: 41.2\n",
        "SDLP: 39.6\n",
        "Steering Entropy: 2.8\n",
        "Lane Keeping Ratio: 0.71\n",
        "Lane Departure Frequency: 3.2\n",
        "SRR: 9.1\n",
        "SAV: 13.4\n",
        "\n",
        "Assistant:\"\"\"\n",
        "\n",
        "# Generate response\n",
        "response = pipe(prompt, max_new_tokens=150, do_sample=False)[0]['generated_text']\n",
        "print(\"✅ Inference Result:\\n\", response[len(prompt):])\n"
      ],
      "metadata": {
        "id": "Wc3xbnIiTxl6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}