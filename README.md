# LLM-based-Agent-for-Driver-Sleepiness-Detection-and-Mitigation-in-Automotive-Systems

**Project Overview**

Driver fatigue is one of the leading causes of road accidents globally, emphasizing the critical need for intelligent systems to detect and mitigate driver sleepiness. This project leverages cutting-edge Large Language Models (LLMs) integrated with multimodal data—including facial expressions, audio signals, driving behavior, and contextual cues—to proactively assess driver alertness levels.


**Key Objectives**

1. Develop a robust multimodal feature extraction framework.

2. Integrate multimodal embeddings (vision, audio, driving data) using Transformer architectures.

3. Utilize LLMs (GPT-4, LLaMA 2) for intelligent decision-making and tailored interventions.

4. Evaluate system effectiveness, reliability, and user satisfaction.
   

**How it Works**

**_Multimodal Data Fusion:_** Vision Transformers, Wav2Vec audio encoders, and Informer Transformers process visual, audio, and driving behavioral data, respectively.

**_Alertness Metrics:_** Real-time driver alertness levels (e.g., alert, drowsy, sleepy) computed through integrated analysis.

**_Interventions:_** Tailored actions such as cabin environment adjustments, conversation initiation, or rest-stop recommendations.


**Technologies & Frameworks**

**_Vision_:** ResNet, ViT (Vision Transformer)

_**Audio Processing:**_ Wav2Vec 2.0

_**Driving Behavior Analysis:**_ Informer Transformer

**_Multimodal Fusion:_** Cross-modal Transformers

_**Decision-Making:**_ GPT-4, LLaMA 2


**Impact & Applications**

1. Improved driver safety through real-time fatigue mitigation.

2. Enhanced automotive systems integrating AI-driven alertness management.

3. Reduction in fatigue-related road accidents.

   
**Supervisor**

Ignacio Alvarez


**Disclaimer**

The details provided here are tentative and subject to change as the project evolves and progresses.

Explore the repository to learn more about our approach, implementation details, and latest updates!
